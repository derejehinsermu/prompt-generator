{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_endpoint = os.getenv('LANGCHAIN_ENDPOINT')\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF Document from local machine\n",
    "local_pdf_path = \"../data/Rich-Dad-Poor-Dad.pdf\"  # Change this to the path of your local PDF\n",
    "\n",
    "# Make sure the file exists\n",
    "if not os.path.exists(local_pdf_path):\n",
    "    raise FileNotFoundError(f\"The file at {local_pdf_path} was not found.\")\n",
    "\n",
    "# Load PDF document\n",
    "loader = PyPDFLoader(local_pdf_path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splits: 539\n"
     ]
    }
   ],
   "source": [
    "# Check embeddings (debug)\n",
    "print(f\"Number of splits: {len(splits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed\n",
    "# vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "# Embed\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(),persist_directory=\"../db/chroma_db\")\n",
    "#load from the disk\n",
    "# vectorstore = Chroma(persist_directory=\"../db/Chroma_db\",embedding = OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_Chroma__query_collection', '_LANGCHAIN_DEFAULT_COLLECTION_NAME', '__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_asimilarity_search_with_relevance_scores', '_client', '_client_settings', '_collection', '_cosine_relevance_score_fn', '_embedding_function', '_euclidean_relevance_score_fn', '_get_retriever_tags', '_max_inner_product_relevance_score_fn', '_persist_directory', '_select_relevance_score_fn', '_similarity_search_with_relevance_scores', 'aadd_documents', 'aadd_texts', 'add_documents', 'add_images', 'add_texts', 'adelete', 'afrom_documents', 'afrom_texts', 'amax_marginal_relevance_search', 'amax_marginal_relevance_search_by_vector', 'as_retriever', 'asearch', 'asimilarity_search', 'asimilarity_search_by_vector', 'asimilarity_search_with_relevance_scores', 'asimilarity_search_with_score', 'delete', 'delete_collection', 'embeddings', 'encode_image', 'from_documents', 'from_texts', 'get', 'max_marginal_relevance_search', 'max_marginal_relevance_search_by_vector', 'override_relevance_score_fn', 'persist', 'search', 'similarity_search', 'similarity_search_by_vector', 'similarity_search_by_vector_with_relevance_scores', 'similarity_search_with_relevance_scores', 'similarity_search_with_score', 'update_document', 'update_documents']\n"
     ]
    }
   ],
   "source": [
    "print(dir(vectorstore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Directly access and print the document splits at specific indices\n",
    "# indices_to_check = [0, 1, 2]\n",
    "# for index in indices_to_check:\n",
    "#     if index < len(splits):\n",
    "#         embedded_doc = splits[index]\n",
    "#         print(f\"Document at index {index}:\")\n",
    "#         print(embedded_doc.page_content)\n",
    "#     else:\n",
    "#         print(f\"Index {index} is out of range.\")\n",
    "\n",
    "# retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Config', 'InputType', 'OutputType', '__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__config__', '__custom_root_type__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__exclude_fields__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_validators__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__include_fields__', '__init__', '__init_subclass__', '__iter__', '__json_encoder__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__orig_bases__', '__parameters__', '__post_root_validators__', '__pre_root_validators__', '__pretty__', '__private_attributes__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__ror__', '__schema_cache__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__try_update_forward_refs__', '__validators__', '__weakref__', '_abatch_with_config', '_abc_impl', '_acall_with_config', '_aget_relevant_documents', '_atransform_stream_with_config', '_batch_with_config', '_calculate_keys', '_call_with_config', '_copy_and_set_values', '_decompose_class', '_enforce_dict_if_root', '_expects_other_args', '_get_relevant_documents', '_get_value', '_init_private_attributes', '_is_protocol', '_iter', '_new_arg_supported', '_transform_stream_with_config', 'aadd_documents', 'abatch', 'abatch_as_completed', 'add_documents', 'aget_relevant_documents', 'ainvoke', 'allowed_search_types', 'assign', 'astream', 'astream_events', 'astream_log', 'atransform', 'batch', 'batch_as_completed', 'bind', 'config_schema', 'config_specs', 'configurable_alternatives', 'configurable_fields', 'construct', 'copy', 'dict', 'from_orm', 'get_graph', 'get_input_schema', 'get_lc_namespace', 'get_name', 'get_output_schema', 'get_prompts', 'get_relevant_documents', 'input_schema', 'invoke', 'is_lc_serializable', 'json', 'lc_attributes', 'lc_id', 'lc_secrets', 'map', 'metadata', 'name', 'output_schema', 'parse_file', 'parse_obj', 'parse_raw', 'pick', 'pipe', 'schema', 'schema_json', 'search_kwargs', 'search_type', 'stream', 'tags', 'to_json', 'to_json_not_implemented', 'transform', 'update_forward_refs', 'validate', 'validate_search_type', 'vectorstore', 'with_config', 'with_fallbacks', 'with_listeners', 'with_retry', 'with_types']\n"
     ]
    }
   ],
   "source": [
    "print(dir(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7ef5f5accc70>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    input_variables=['context', 'question'],\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['context', 'question'],\n",
    "                template=(\n",
    "                    \"You are an assistant for question-answering tasks. Only use the following pieces of retrieved context to answer the question. \"\n",
    "                    \"Do not use any outside knowledge. If you don't know the answer based on the context, just say that you don't know. \"\n",
    "                    \"Use three sentences maximum and keep the answer concise.\\n\"\n",
    "                    \"Question: {question} \\n\"\n",
    "                    \"Context: {context} \\n\"\n",
    "                    \"Answer:\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert Kiyosaki is an entrepreneur, educator, and investor known for his financial education teachings and the book \"Rich Dad Poor Dad.\" He challenges conventional wisdom on money and investing and encourages people to become financially educated. Kiyosaki is the founder of The Rich Dad Company and has launched a new offering in mobile and online gaming.\n"
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "def create_rag_chain(retriever, prompt_template, llm):\n",
    "    return (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt_template\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "rag_chain = create_rag_chain(retriever, prompt_template, llm)\n",
    "\n",
    "# Question\n",
    "response = rag_chain.invoke(\"who is Robert\")\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(local_pdf_path):\n",
    "    # Load and split PDF document\n",
    "    loader = PyPDFLoader(local_pdf_path)\n",
    "    docs = loader.load_and_split()\n",
    "\n",
    "    # Split\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Embed\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "\n",
    "    retriever = vectorstore.as_retriever()\n",
    "else:\n",
    "    retriever = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "#### PROMPT GENERATION ####\n",
    "\n",
    "def generate_optimized_prompts(query, num_prompts=2):\n",
    "    # Initialize ChatOpenAI\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "    # Define the base prompt\n",
    "    base_prompt = f\"User Query: {query}\\n\\nGenerate an optimized prompt:\"\n",
    "\n",
    "    # Use the retriever to get relevant context from the user's documents (if available)\n",
    "    context_text = \"\"\n",
    "    if retriever:\n",
    "        context = retriever.get_relevant_documents(query)\n",
    "        if context:\n",
    "            context_text = \"\\n\\n\".join(doc.page_content for doc in context)\n",
    "\n",
    "    # Generate multiple optimized prompts using ChatOpenAI with the retrieved context\n",
    "    generated_prompts = []\n",
    "    for _ in range(num_prompts):\n",
    "        messages = [\n",
    "            AIMessage(content=\"\"\"\n",
    "                      \"You are an assistant specialized in generating optimized prompts. \n",
    "                      example1:original prompmt :Interior furniture design with rocks. and \n",
    "                      optimized prompt:Interior furniture design with rocks, rustic, earthy, minimalist, natural, organic, textured, contemporary, modern, Scandinavian, zen, Japanese, wood, stone, sustainable, eco-friendly, neutral colors, clean lines, spatial, cozy.\n",
    "                      example2:Write me programming job candidate requirements and optimized prompt\n",
    "                      You are a senior software engineer responsible for assessing the ideal candidate for a programming job. Your role involves analyzing technical skills, experience, and personality traits that contribute to successful software development. With extensive knowledge of programming languages, frameworks, and algorithms, you can accurately evaluate candidates' potential to excel in the field. As an expert in this domain, you can easily identify the qualities necessary to thrive in a programming role. Please provide a detailed yet concise description of the ideal candidate, covering technical skills, personal qualities, communication abilities, and work experience. Focus your knowledge and experience on creating a guide for our recruiting process.\n",
    "\n",
    "                      \"\"\"),\n",
    "            HumanMessage(content=base_prompt + \"\\n\\nContext: \" + context_text)\n",
    "        ]\n",
    "        response = llm(messages=messages)\n",
    "        generated_prompts.append(response.content.strip())\n",
    "    return generated_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: write a python program that adds two integer numbers\n",
      "Optimized Prompt: Optimized Prompt:\n",
      "Write a Python program that takes two integer numbers as input and adds them together. The program should prompt the user to enter the two numbers, perform the addition operation, and then display the result. Make sure to handle any potential errors that may occur during user input or calculation.\n",
      "\n",
      "Context:\n",
      "In a bustling city like Singapore, where talent and expertise converge, individuals with diverse skills and abilities contribute to the vibrant atmosphere. From skilled professionals to talented artisans, the city is a melting pot of creativity and innovation. As you navigate through the dynamic streets, you encounter stories of ingenuity and resourcefulness, like the young mechanic who swiftly diagnosed and fixed a car engine issue with precision and expertise. These encounters remind us of the remarkable individuals who shape our world with their knowledge and dedication.\n",
      "\n",
      "Bonus Book Excerpt:\n",
      "Amidst the urban hustle and bustle, a sense of awe and admiration fills the air as stories of remarkable individuals unfold. From the skilled mechanic who effortlessly diagnosed a car issue to the talented professionals who excel in their respective fields, the city pulsates with energy and talent. Each encounter serves as a testament to the power of expertise and ingenuity, inspiring those around to strive for excellence in their endeavors.\n",
      "\n",
      "Optimized Prompt: Here is an optimized prompt based on your query:\n",
      "\n",
      "\"Write a Python program that adds two integer numbers. Utilize the input function to take user input for the two numbers, perform the addition operation, and display the result. Ensure that the program handles potential errors, such as invalid inputs or non-integer values. Consider incorporating comments to explain the logic of the code and enhance readability.\"\n",
      "\n",
      "Bonus:\n",
      "Book Excerpt: She put the rest of her notes away and hurried out through the large glass doors into the humid Singapore morning. At least she gave me a fair and favorable write-up the next morning. The world is filled with smart, talented, educated, and gifted people. We meet them every day. They are all around us. A few days ago, my car was not running well. I pulled into a garage, and the young mechanic had it fixed in just a few minutes. He knew what was wrong by simply listening to the engine. I was amazed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "queries = \"write a python program that adds two integer numbers\"\n",
    "# queries = \"Write me programming job candidate requirements\"\n",
    "\n",
    "# queries = ' what does it mean poor dad and rich dad in the books of rebort'\n",
    "\n",
    "# for query in queries:\n",
    "    # Generate multiple optimized prompts using RAG\n",
    "generated_prompts = generate_optimized_prompts(queries)\n",
    "\n",
    "# Print the generated prompts\n",
    "print(f\"Query: {queries}\")\n",
    "for prompt in generated_prompts:\n",
    "    print(f\"Optimized Prompt: {prompt}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate Code Goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
